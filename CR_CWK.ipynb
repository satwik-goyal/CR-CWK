{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satwik-goyal/CR-CWK/blob/main/CR_CWK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IB1vjS2tkUoY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Reshape , Multiply, Activation\n",
        "from tensorflow.keras.layers import Input, DepthwiseConv2D, GlobalAveragePooling2D , Add\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.optimizers.legacy import RMSprop, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load CIFAR100 dataset\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)"
      ],
      "metadata": {
        "id": "83xXmrVpPoHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888f5d89-2b0d-45d5-dacb-820f122d86d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the data \" , X_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLOeLB5yXxEo",
        "outputId": "9b39c96b-0a99-486d-a153-ef8b0241597e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the data  (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Selected_Image = 2\n",
        "image = X_train[Selected_Image]\n",
        "print (\"Sample input image: \" + str(image))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FhxTAla0W7Kn",
        "outputId": "6ad3c07b-6c16-43c3-db28-72f8dc5ee030"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input image: [[[0.98039216 0.98039216 0.972549  ]\n",
            "  [0.972549   0.9764706  0.9529412 ]\n",
            "  [0.96862745 0.972549   0.9372549 ]\n",
            "  ...\n",
            "  [0.98039216 0.98039216 0.9647059 ]\n",
            "  [0.98039216 0.98039216 0.9647059 ]\n",
            "  [0.9764706  0.98039216 0.9647059 ]]\n",
            "\n",
            " [[0.98039216 0.9843137  0.9607843 ]\n",
            "  [0.972549   0.9764706  0.93333334]\n",
            "  [0.96862745 0.96862745 0.91764706]\n",
            "  ...\n",
            "  [0.9843137  0.9843137  0.9490196 ]\n",
            "  [0.9843137  0.9882353  0.9529412 ]\n",
            "  [0.98039216 0.9843137  0.9529412 ]]\n",
            "\n",
            " [[0.9843137  0.9843137  0.95686275]\n",
            "  [0.98039216 0.972549   0.92941177]\n",
            "  [0.98039216 0.9607843  0.9137255 ]\n",
            "  ...\n",
            "  [0.98039216 0.9764706  0.93333334]\n",
            "  [0.98039216 0.9764706  0.9411765 ]\n",
            "  [0.98039216 0.9764706  0.9490196 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8666667  0.8352941  0.7490196 ]\n",
            "  [0.8666667  0.80784315 0.6901961 ]\n",
            "  [0.88235295 0.8117647  0.70980394]\n",
            "  ...\n",
            "  [0.78039217 0.6901961  0.5254902 ]\n",
            "  [0.8117647  0.75686276 0.64705884]\n",
            "  [0.9137255  0.8980392  0.8862745 ]]\n",
            "\n",
            " [[0.88235295 0.8745098  0.8       ]\n",
            "  [0.8901961  0.85882354 0.76862746]\n",
            "  [0.8980392  0.84705883 0.78431374]\n",
            "  ...\n",
            "  [0.8        0.7254902  0.5921569 ]\n",
            "  [0.83137256 0.7882353  0.7058824 ]\n",
            "  [0.91764706 0.9098039  0.89411765]]\n",
            "\n",
            " [[0.9137255  0.9137255  0.8862745 ]\n",
            "  [0.91764706 0.9098039  0.8784314 ]\n",
            "  [0.92156863 0.9019608  0.88235295]\n",
            "  ...\n",
            "  [0.85882354 0.81960785 0.7607843 ]\n",
            "  [0.8745098  0.84705883 0.8117647 ]\n",
            "  [0.9098039  0.9019608  0.89411765]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def EfficientNet(input_shape, num_classes):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "\n",
        "#     # Base Block\n",
        "#     x = Conv2D(256, (3, 3), padding='same', activation='swish')(inputs)\n",
        "#     x = BatchNormalization()(x)\n",
        "\n",
        "#     # Middle Block (Repeat this block multiple times)\n",
        "#     for _ in range(7):\n",
        "#       x = DepthwiseConv2D((3, 3), padding='same', activation='swish')(x)\n",
        "#       x = BatchNormalization()(x)\n",
        "\n",
        "#       # Squeeze and excitation\n",
        "#       se = GlobalAveragePooling2D()(x)\n",
        "#       se = Reshape((1, 1, int(x.shape[-1])))(se)\n",
        "#       se = Dense(int(x.shape[-1]) // 32, activation='swish')(se)\n",
        "#       se = Dense(int(x.shape[-1]), activation='sigmoid')(se)\n",
        "#       se = Reshape((1, 1, int(x.shape[-1])))(se)\n",
        "#       x = Multiply()([x, se])\n",
        "#       x = Conv2D(128, (1, 1), padding='same', activation='swish')(x)\n",
        "#       x = BatchNormalization()(x)\n",
        "#       x = Dropout(0.2)(x)\n",
        "\n",
        "#     # Top Block\n",
        "#     x = GlobalAveragePooling2D()(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "#     x = Dense(256, activation='softmax')(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "#     x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     # Create the model\n",
        "#     model = tf.keras.Model(inputs, x)\n",
        "\n",
        "#     return model\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(input_shape = (32,32,3) , include_top= False , weights=\"imagenet\",\n",
        "    classes=100)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D(name=\"avg_pool\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2, name=\"top_dropout\"))\n",
        "model.add(Dense(100 , activation=\"softmax\", name=\"pred\"))\n",
        "model.compile(optimizer= Adam(learning_rate=1e-2), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "EYisc-P_-lTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb2e376-0d84-46dd-e832-feb660df1f9e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = EfficientNet((32,32,3),100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7L_yOz_-vy7",
        "outputId": "ce85ac4f-632b-46e5-d45f-719379692f19"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)              0         \n",
            " ling2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_50 (Ba  (None, 2048)              8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " top_dropout (Dropout)       (None, 2048)              0         \n",
            "                                                                 \n",
            " pred (Dense)                (None, 100)               204900    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23800804 (90.79 MB)\n",
            "Trainable params: 23743588 (90.57 MB)\n",
            "Non-trainable params: 57216 (223.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size = 128 , epochs = 100 , validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DZgfPaxs-95Z",
        "outputId": "8aee32ac-956d-4265-8903-3a4d604d6210"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "352/352 [==============================] - 32s 72ms/step - loss: 5.9480 - accuracy: 0.0124 - val_loss: 4.6517 - val_accuracy: 0.0106\n",
            "Epoch 2/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 4.5407 - accuracy: 0.0233 - val_loss: 4.4943 - val_accuracy: 0.0226\n",
            "Epoch 3/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 4.3346 - accuracy: 0.0356 - val_loss: 4.2900 - val_accuracy: 0.0454\n",
            "Epoch 4/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 4.1420 - accuracy: 0.0577 - val_loss: 7.5360 - val_accuracy: 0.0388\n",
            "Epoch 5/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 4.0569 - accuracy: 0.0694 - val_loss: 4.0494 - val_accuracy: 0.0780\n",
            "Epoch 6/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.9500 - accuracy: 0.0865 - val_loss: 91.3168 - val_accuracy: 0.0556\n",
            "Epoch 7/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.8271 - accuracy: 0.1026 - val_loss: 8.5451 - val_accuracy: 0.0920\n",
            "Epoch 8/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 3.8227 - accuracy: 0.1038 - val_loss: 3.8088 - val_accuracy: 0.1090\n",
            "Epoch 9/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.6755 - accuracy: 0.1263 - val_loss: 10.6015 - val_accuracy: 0.0864\n",
            "Epoch 10/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.6543 - accuracy: 0.1312 - val_loss: 3.7741 - val_accuracy: 0.1260\n",
            "Epoch 11/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.6093 - accuracy: 0.1407 - val_loss: 10.7552 - val_accuracy: 0.1530\n",
            "Epoch 12/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.6746 - accuracy: 0.1343 - val_loss: 6.2586 - val_accuracy: 0.1218\n",
            "Epoch 13/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.6065 - accuracy: 0.1442 - val_loss: 5.0576 - val_accuracy: 0.1396\n",
            "Epoch 14/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.5120 - accuracy: 0.1584 - val_loss: 4.5723 - val_accuracy: 0.1628\n",
            "Epoch 15/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 3.5364 - accuracy: 0.1578 - val_loss: 18559.4023 - val_accuracy: 0.0538\n",
            "Epoch 16/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.4382 - accuracy: 0.1792 - val_loss: 3.8577 - val_accuracy: 0.1814\n",
            "Epoch 17/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.2236 - accuracy: 0.2057 - val_loss: 3.8145 - val_accuracy: 0.2116\n",
            "Epoch 18/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 3.1252 - accuracy: 0.2280 - val_loss: 4.1587 - val_accuracy: 0.2378\n",
            "Epoch 19/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 3.0102 - accuracy: 0.2482 - val_loss: 3.1414 - val_accuracy: 0.2480\n",
            "Epoch 20/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.9309 - accuracy: 0.2650 - val_loss: 3.0468 - val_accuracy: 0.2486\n",
            "Epoch 21/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.8217 - accuracy: 0.2862 - val_loss: 3.3515 - val_accuracy: 0.2328\n",
            "Epoch 22/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.6904 - accuracy: 0.3110 - val_loss: 3.4464 - val_accuracy: 0.2206\n",
            "Epoch 23/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.6926 - accuracy: 0.3213 - val_loss: 4.5506 - val_accuracy: 0.1694\n",
            "Epoch 24/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 2.9389 - accuracy: 0.2790 - val_loss: 49.2956 - val_accuracy: 0.1202\n",
            "Epoch 25/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 3.0800 - accuracy: 0.2489 - val_loss: 20.3111 - val_accuracy: 0.2372\n",
            "Epoch 26/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.6528 - accuracy: 0.3249 - val_loss: 23.8065 - val_accuracy: 0.2240\n",
            "Epoch 27/100\n",
            "352/352 [==============================] - 24s 68ms/step - loss: 2.5090 - accuracy: 0.3547 - val_loss: 15.7959 - val_accuracy: 0.2412\n",
            "Epoch 28/100\n",
            "352/352 [==============================] - 25s 70ms/step - loss: 2.4184 - accuracy: 0.3751 - val_loss: 4.2574 - val_accuracy: 0.3104\n",
            "Epoch 29/100\n",
            "352/352 [==============================] - 25s 70ms/step - loss: 2.4417 - accuracy: 0.3724 - val_loss: 6.4717 - val_accuracy: 0.2856\n",
            "Epoch 30/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 2.2860 - accuracy: 0.4060 - val_loss: 3.3855 - val_accuracy: 0.3028\n",
            "Epoch 31/100\n",
            "352/352 [==============================] - 25s 71ms/step - loss: 2.4266 - accuracy: 0.3801 - val_loss: 21.4112 - val_accuracy: 0.2430\n",
            "Epoch 32/100\n",
            "352/352 [==============================] - 24s 69ms/step - loss: 2.2592 - accuracy: 0.4094 - val_loss: 3.8162 - val_accuracy: 0.2676\n",
            "Epoch 33/100\n",
            "107/352 [========>.....................] - ETA: 16s - loss: 2.0141 - accuracy: 0.4607"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e4e37be75f3f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.evaluate(X_test , y_test)"
      ],
      "metadata": {
        "id": "CJKA5OQluOKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a0f036-ae67-4269-baf1-f9745773af97"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 20.4742 - accuracy: 0.3335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_E-RTXzAN_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}