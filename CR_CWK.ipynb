{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMswc/K4Xeffd29pHVjh9g5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satwik-goyal/CR-CWK/blob/main/CR_CWK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IB1vjS2tkUoY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Reshape , Multiply\n",
        "from tensorflow.keras.layers import Input, DepthwiseConv2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.optimizers.legacy import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load CIFAR100 dataset\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83xXmrVpPoHc",
        "outputId": "7cd75471-3655-49ce-e917-c76c16c6eea8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the data \" , X_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLOeLB5yXxEo",
        "outputId": "af8891b4-da74-486b-de79-38694f264f0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the data  (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Selected_Image = 2\n",
        "image = X_train[Selected_Image]\n",
        "print (\"Sample input image: \" + str(image))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FhxTAla0W7Kn",
        "outputId": "ad84e3a0-6d6b-4cb2-e3cc-c6742e33da87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input image: [[[0.98039216 0.98039216 0.972549  ]\n",
            "  [0.972549   0.9764706  0.9529412 ]\n",
            "  [0.96862745 0.972549   0.9372549 ]\n",
            "  ...\n",
            "  [0.98039216 0.98039216 0.9647059 ]\n",
            "  [0.98039216 0.98039216 0.9647059 ]\n",
            "  [0.9764706  0.98039216 0.9647059 ]]\n",
            "\n",
            " [[0.98039216 0.9843137  0.9607843 ]\n",
            "  [0.972549   0.9764706  0.93333334]\n",
            "  [0.96862745 0.96862745 0.91764706]\n",
            "  ...\n",
            "  [0.9843137  0.9843137  0.9490196 ]\n",
            "  [0.9843137  0.9882353  0.9529412 ]\n",
            "  [0.98039216 0.9843137  0.9529412 ]]\n",
            "\n",
            " [[0.9843137  0.9843137  0.95686275]\n",
            "  [0.98039216 0.972549   0.92941177]\n",
            "  [0.98039216 0.9607843  0.9137255 ]\n",
            "  ...\n",
            "  [0.98039216 0.9764706  0.93333334]\n",
            "  [0.98039216 0.9764706  0.9411765 ]\n",
            "  [0.98039216 0.9764706  0.9490196 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8666667  0.8352941  0.7490196 ]\n",
            "  [0.8666667  0.80784315 0.6901961 ]\n",
            "  [0.88235295 0.8117647  0.70980394]\n",
            "  ...\n",
            "  [0.78039217 0.6901961  0.5254902 ]\n",
            "  [0.8117647  0.75686276 0.64705884]\n",
            "  [0.9137255  0.8980392  0.8862745 ]]\n",
            "\n",
            " [[0.88235295 0.8745098  0.8       ]\n",
            "  [0.8901961  0.85882354 0.76862746]\n",
            "  [0.8980392  0.84705883 0.78431374]\n",
            "  ...\n",
            "  [0.8        0.7254902  0.5921569 ]\n",
            "  [0.83137256 0.7882353  0.7058824 ]\n",
            "  [0.91764706 0.9098039  0.89411765]]\n",
            "\n",
            " [[0.9137255  0.9137255  0.8862745 ]\n",
            "  [0.91764706 0.9098039  0.8784314 ]\n",
            "  [0.92156863 0.9019608  0.88235295]\n",
            "  ...\n",
            "  [0.85882354 0.81960785 0.7607843 ]\n",
            "  [0.8745098  0.84705883 0.8117647 ]\n",
            "  [0.9098039  0.9019608  0.89411765]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def EfficientNet(input_shape, num_classes):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Base Block\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Middle Block (Repeat this block multiple times)\n",
        "    for _ in range(3):\n",
        "        x = DepthwiseConv2D((3, 3), padding='same', activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Squeeze and excitation\n",
        "        se = GlobalAveragePooling2D()(x)\n",
        "        se = Reshape((1, 1, int(x.shape[-1])))(se)\n",
        "        se = Dense(int(x.shape[-1]) // 16, activation='relu')(se)\n",
        "        se = Dense(int(x.shape[-1]), activation='sigmoid')(se)\n",
        "        se = Reshape((1, 1, int(x.shape[-1])))(se)\n",
        "        x = Multiply()([x, se])\n",
        "\n",
        "\n",
        "        x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "    # Top Block\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "q-4Htyl_WP9U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create the model\n",
        "model = EfficientNet(input_shape=(32, 32, 3), num_classes=100)\n",
        "\n",
        "# Compile the model\n",
        "opt = RMSprop(learning_rate=1e-2, decay=1e-6)\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "fSNalSrLWP7E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "GNpBjsIiWP4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save(\"Model_lr-001.Efficientnet\")"
      ],
      "metadata": {
        "id": "z7X5FBKMWP2d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load_1 = load_model(\"Model_lr-001.Efficientnet\")"
      ],
      "metadata": {
        "id": "D_ca9SVGWPz9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_load_1.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgUlFz-WWPwm",
        "outputId": "9085d785-49c4-420b-b9ff-7d16f3b08c9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 10ms/step - loss: 3.3145 - accuracy: 0.3055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "# # Create a sequential model\n",
        "# model_2 = tf.keras.Sequential()\n",
        "\n",
        "# # Add convolutional layers\n",
        "# model_2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "# model_2.add(BatchNormalization())\n",
        "# model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model_2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model_2.add(BatchNormalization())\n",
        "# model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model_2.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# model_2.add(BatchNormalization())\n",
        "# model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model_2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model_2.add(BatchNormalization())\n",
        "# model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model_2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model_2.add(BatchNormalization())\n",
        "# model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# # Flatten the output\n",
        "# model_2.add(Flatten())\n",
        "\n",
        "# # Add fully connected layers\n",
        "# model_2.add(Dense(512, activation='relu'))\n",
        "# model_2.add(Dropout(0.5))  # Add dropout for regularization\n",
        "\n",
        "# model_2.add(Dense(256, activation='relu'))\n",
        "# model_2.add(Dropout(0.3))  # More dropout\n",
        "\n",
        "# model_2.add(Dense(100, activation='softmax'))  # 100 classes for CIFAR-100\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Activation, GlobalAveragePooling2D, Multiply\n",
        "\n",
        "# Create a sequential model\n",
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model_2.add(SeparableConv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model_2.add(SeparableConv2D(128, (3, 3), padding='same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model_2.add(SeparableConv2D(256, (3, 3), padding='same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model_2.add(SeparableConv2D(128, (3, 3), padding='same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model_2.add(SeparableConv2D(64, (3, 3), padding='same'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Squeeze-and-Excitation Block\n",
        "squeeze = GlobalAveragePooling2D()(model_2.output)\n",
        "excitation = Dense(64 // 16, activation='relu')(squeeze)\n",
        "excitation = Dense(64, activation='sigmoid')(excitation)\n",
        "excitation = Multiply()([model_2.output, excitation])\n",
        "\n",
        "# Flatten the output\n",
        "model_2.add(Flatten())\n",
        "\n",
        "# Add fully connected layers\n",
        "model_2.add(Dense(512, activation='swish'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(256, activation='swish'))\n",
        "model_2.add(Dropout(0.3))\n",
        "model_2.add(Dense(100, activation='softmax'))\n",
        "# Compile the model\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_2.fit(X_train, y_train, epochs=50, batch_size=128, validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPVoBfqpmv7n",
        "outputId": "0e677065-34b4-4f68-ff53-aff893169a5f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 89s 25ms/step - loss: 3.8084 - accuracy: 0.1123 - val_loss: 5.0874 - val_accuracy: 0.0090\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.1748 - accuracy: 0.2123 - val_loss: 3.0675 - val_accuracy: 0.2416\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.8723 - accuracy: 0.2698 - val_loss: 2.9470 - val_accuracy: 0.2564\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.6812 - accuracy: 0.3073 - val_loss: 2.8662 - val_accuracy: 0.2830\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.5255 - accuracy: 0.3391 - val_loss: 3.0663 - val_accuracy: 0.2778\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.3924 - accuracy: 0.3714 - val_loss: 2.6352 - val_accuracy: 0.3278\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.2856 - accuracy: 0.3895 - val_loss: 2.6976 - val_accuracy: 0.3098\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 2.1922 - accuracy: 0.4084 - val_loss: 2.7717 - val_accuracy: 0.3164\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.1007 - accuracy: 0.4302 - val_loss: 2.6890 - val_accuracy: 0.3302\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.0272 - accuracy: 0.4432 - val_loss: 2.6904 - val_accuracy: 0.3342\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.9566 - accuracy: 0.4583 - val_loss: 2.8949 - val_accuracy: 0.3142\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.8912 - accuracy: 0.4732 - val_loss: 2.6714 - val_accuracy: 0.3472\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.8343 - accuracy: 0.4873 - val_loss: 3.6327 - val_accuracy: 0.2600\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 1.7836 - accuracy: 0.4998 - val_loss: 2.8527 - val_accuracy: 0.3432\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.7311 - accuracy: 0.5090 - val_loss: 2.7005 - val_accuracy: 0.3544\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6803 - accuracy: 0.5199 - val_loss: 2.9476 - val_accuracy: 0.3320\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6435 - accuracy: 0.5284 - val_loss: 3.2496 - val_accuracy: 0.3014\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.6021 - accuracy: 0.5374 - val_loss: 2.7573 - val_accuracy: 0.3592\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.5650 - accuracy: 0.5476 - val_loss: 3.3961 - val_accuracy: 0.2960\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.5228 - accuracy: 0.5558 - val_loss: 2.8646 - val_accuracy: 0.3530\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.4952 - accuracy: 0.5633 - val_loss: 2.8318 - val_accuracy: 0.3472\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.4574 - accuracy: 0.5707 - val_loss: 2.9904 - val_accuracy: 0.3468\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4187 - accuracy: 0.5831 - val_loss: 3.1822 - val_accuracy: 0.3234\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.3996 - accuracy: 0.5884 - val_loss: 3.0880 - val_accuracy: 0.3446\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.3710 - accuracy: 0.5908 - val_loss: 3.0523 - val_accuracy: 0.3516\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3440 - accuracy: 0.5995 - val_loss: 3.5330 - val_accuracy: 0.2914\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.3297 - accuracy: 0.6020 - val_loss: 3.2277 - val_accuracy: 0.3416\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.2973 - accuracy: 0.6129 - val_loss: 3.2187 - val_accuracy: 0.3368\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2788 - accuracy: 0.6148 - val_loss: 3.5492 - val_accuracy: 0.2946\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2627 - accuracy: 0.6177 - val_loss: 3.8703 - val_accuracy: 0.2850\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2354 - accuracy: 0.6250 - val_loss: 3.3195 - val_accuracy: 0.3286\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2129 - accuracy: 0.6307 - val_loss: 3.4925 - val_accuracy: 0.3188\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.1890 - accuracy: 0.6392 - val_loss: 3.4016 - val_accuracy: 0.3348\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1829 - accuracy: 0.6357 - val_loss: 3.3947 - val_accuracy: 0.3288\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.1759 - accuracy: 0.6395 - val_loss: 3.2013 - val_accuracy: 0.3482\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.1429 - accuracy: 0.6494 - val_loss: 3.3456 - val_accuracy: 0.3432\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1353 - accuracy: 0.6528 - val_loss: 3.4803 - val_accuracy: 0.3366\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.1243 - accuracy: 0.6536 - val_loss: 3.4127 - val_accuracy: 0.3380\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1082 - accuracy: 0.6566 - val_loss: 3.4681 - val_accuracy: 0.3456\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.0926 - accuracy: 0.6613 - val_loss: 3.6517 - val_accuracy: 0.3308\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.0742 - accuracy: 0.6702 - val_loss: 3.5002 - val_accuracy: 0.3398\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.0654 - accuracy: 0.6690 - val_loss: 3.4355 - val_accuracy: 0.3358\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.0609 - accuracy: 0.6694 - val_loss: 3.7505 - val_accuracy: 0.3150\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.0455 - accuracy: 0.6738 - val_loss: 3.8007 - val_accuracy: 0.3250\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.0365 - accuracy: 0.6765 - val_loss: 3.9517 - val_accuracy: 0.3102\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.0323 - accuracy: 0.6790 - val_loss: 3.7891 - val_accuracy: 0.3190\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.0133 - accuracy: 0.6829 - val_loss: 3.6679 - val_accuracy: 0.3312\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.9994 - accuracy: 0.6864 - val_loss: 3.6688 - val_accuracy: 0.3366\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.9929 - accuracy: 0.6873 - val_loss: 3.8911 - val_accuracy: 0.3210\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.9821 - accuracy: 0.6931 - val_loss: 3.8710 - val_accuracy: 0.3192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb7bc3651b0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIIF6YEtm427",
        "outputId": "170a33ce-ffe3-48a9-df04-64b90024e9c0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 3.7646 - accuracy: 0.3361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW18TTbqu4fK",
        "outputId": "8d1bef93-ecb7-4308-d180-6dd55fa5e2a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.7646195888519287, 0.3361000120639801]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Activation, GlobalAveragePooling2D, Multiply\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create a sequential model\n",
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model_2.add(SeparableConv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), kernel_regularizer=l2(0.001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(SeparableConv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "model_2.add(Dropout(0.3))\n",
        "\n",
        "model_2.add(SeparableConv2D(256, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('swish'))\n",
        "model_2.add(MaxPooling2D((2, 2)))\n",
        "model_2.add(Dropout(0.4))\n",
        "\n",
        "# Squeeze-and-Excitation Block\n",
        "squeeze = GlobalAveragePooling2D()(model_2.output)\n",
        "excitation = Dense(256 // 16, activation='swish')(squeeze)\n",
        "excitation = Dense(256, activation='sigmoid')(excitation)\n",
        "excitation = Multiply()([model_2.output, excitation])\n",
        "\n",
        "# Flatten the output\n",
        "model_2.add(Flatten())\n",
        "\n",
        "# Add fully connected layers\n",
        "model_2.add(Dense(512, activation='swish', kernel_regularizer=l2(0.001)))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(256, activation='swish', kernel_regularizer=l2(0.001)))\n",
        "model_2.add(Dropout(0.4))\n",
        "model_2.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "model_2.fit(train_datagen.flow(X_train, y_train, batch_size=64),\n",
        "            steps_per_epoch=len(X_train) // 64,\n",
        "            epochs=100,\n",
        "            validation_data=val_datagen.flow(X_test, y_test, batch_size=64),\n",
        "            validation_steps=len(X_test) // 64,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "EGmkQzBFu57S",
        "outputId": "0bb34b81-ea1e-41d6-f598-72c686814fc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5803bd95df51>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train the model with data augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m model_2.fit(train_datagen.flow(X_train, y_train, batch_size=64),\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyKglXegzPNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}